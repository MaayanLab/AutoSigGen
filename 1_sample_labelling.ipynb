{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b779492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde97bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "species=\"mouse\"\n",
    "gsm4sig_version = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dba8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_study_meta = pd.read_csv(\"data/\"+species+\"_bulk_study_meta.csv\", index_col=0)\n",
    "frequent_terms = pd.read_csv(f\"data/{species}v{gsm4sig_version}_frequent_terms.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_terms\n",
    "# Category 0: Neutral\n",
    "# Category 1: Control term\n",
    "# Category 2: Perturbation term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8cb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_study_meta[\"sample_title_set\"] = (bulk_study_meta[\"sample_title\"]             # processing the sample titles by \n",
    "                                       .str.lower().str.findall(r\"[a-z]+\")         # extracting the keywords and \n",
    "                                       .apply(frozenset))                          # saving them as a (frozen) set\n",
    "\n",
    "ctrl_set = set(frequent_terms.loc[frequent_terms[\"Category\"] == 1][\"Label\"])\n",
    "pert_set = set(frequent_terms.loc[frequent_terms[\"Category\"] == 2][\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e151f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_study_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cp(test_set, ctrl_set = ctrl_set, pert_set = pert_set): # categorizes sample as ctrl or pert\n",
    "    difference = len(test_set & ctrl_set) - len(test_set & pert_set)   # 0 - undetermined\n",
    "    if difference == 0: return 0                                       # 1 - control group\n",
    "    return 1 if difference > 0 else 2                                  # 2 - perturbation group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_study_meta[\"cp_group\"] = bulk_study_meta[\"sample_title_set\"].apply(categorize_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bulk_study_meta[\"series_id\"].unique()) # unique studies before filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c73dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_undet = []\n",
    "for gse in bulk_study_meta.groupby(\"series_id\")[\"sample_title_set\"]:   \n",
    "    if ((gse[1].value_counts() >= 2).all()): no_undet.append(gse[0])  # keeping studies where theres >= 2 samples per category\n",
    "        \n",
    "no_undet_study = bulk_study_meta[bulk_study_meta[\"series_id\"].isin(no_undet)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_undet)                            # unique studies post filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68085c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gse_per_term = []                                                                              # counts unique gse for each \n",
    "#def det_gse(test_set, term): return 1 if len(test_set & {term}) > 0 else 0                     # control or perturbation term\n",
    "#for i in frequent_terms[\"Label\"]:\n",
    "#    bulk_study_meta[\"det_gse\"] = bulk_study_meta[\"sample_title_set\"].apply(det_gse, term=i)\n",
    "#    gse_per_term.append(len(bulk_study_meta.loc[bulk_study_meta[\"det_gse\"] == 1][\"series_id\"].unique()))\n",
    "#    bulk_study_meta[\"det_gse\"] = np.zeros(162372)\n",
    "    \n",
    "#frequent_terms[\"num_gse\"] = gse_per_term\n",
    "#frequent_terms.to_csv(species+\"_frequent_terms_gse_count.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbee8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def gsm_title_cluster(series, cluster_esp = 0.01, cluster_min_samp = 2):                     # grouping gsm by clustering words\n",
    "#    mlb = MultiLabelBinarizer()\n",
    "#    term_mat = mlb.fit_transform(series[\"sample_title_set\"])\n",
    "#    if 1 in term_mat.shape: return np.zeros(len(series)).astype(int)\n",
    "#    pca = PCA()\n",
    "#    pca.fit(term_mat.T)\n",
    "#    clustering = DBSCAN(eps=0.01, min_samples=2)\n",
    "#    #print(list(zip(pca.components_[0], pca.components_[1])))\n",
    "#    #clustering.fit(list(zip(pca.components_[0], pca.components_[1])))\n",
    "#    clustering.fit(pca.components_[0].reshape(-1, 1))\n",
    "#    return clustering.labels_\n",
    "\n",
    "\n",
    "# for gse in no_undet_study[\"series_id\"].unique():\n",
    "#    series = no_undet_study.loc[no_undet_study[\"series_id\"] == gse]\n",
    "#    no_undet_study.loc[no_undet_study[\"series_id\"] == gse, \"gsm_cluster\"] = gsm_title_cluster(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_series(series):\n",
    "    '''\n",
    "    Categorize an input series and return (undet, ctrl, pert) tuple\n",
    "    '''\n",
    "    series_counter = (Counter(list(zip(*series.groupby([\"cp_group\", \"sample_title_set\"])\n",
    "                                       .groups.keys()))[0]))\n",
    "                                          # Subgroup counts for:\n",
    "    return (min(series_counter[0], 3),    # undetermined group\n",
    "            min(series_counter[1], 3),    # control group\n",
    "            min(series_counter[2], 3))    # perturbation group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fbdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse_types = {}\n",
    "for n, gse in tqdm(enumerate(no_undet_study[\"series_id\"].unique())):               # categorizing each of the filtered study\n",
    "    series = no_undet_study.loc[no_undet_study[\"series_id\"] == gse]\n",
    "    gse_types[gse] = count_series(series)\n",
    "    \n",
    "categorized_gse = pd.DataFrame({\"gse\":gse_types.keys(), \"gse_type\":gse_types.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ced86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(?, c, p)    freq   3 := >2\")\n",
    "print(categorized_gse[\"gse_type\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrap_score(study_cat):\n",
    "    '''\n",
    "    Determine extrapolation score for a given study category tuple by \n",
    "    penalizing each of inferred type (ctrl, pert) and direction\n",
    "    '''\n",
    "    undet, ctrl, pert = study_cat\n",
    "    score = 0\n",
    "    if undet == 0 or pert == 0:                 #(0, x, y) or (y, x, 0)\n",
    "        if ctrl == 1:                           #(0, 1, y) or (y, 1, 0)\n",
    "            if undet != 0: score += 1           #penalty for inferred pert\n",
    "        if ctrl < 1:                            #(0, 0, y) or (y, 0, 0)\n",
    "            score += 1                          #penalty for inferred ctrl\n",
    "            score += 2 if undet != 0 else 1     #penalty for inferred direction and/or inferred pert\n",
    "    else:\n",
    "        if ctrl < 1:                            #(x, 0, y)\n",
    "            score += 1 if undet == 1 else -1    #penality for inferred ctrl\n",
    "        else:\n",
    "            score = -1                          #unaccounted for\n",
    "    return score\n",
    "        \n",
    "\n",
    "def to_calc_sig_format(study_cat, studies = no_undet_study, categorized_gse = categorized_gse):\n",
    "    '''\n",
    "    Convert studies corresponding to an input study category type to \n",
    "    a signature-calculation-friendly dataframe format with rows: \n",
    "    gse, [ctrl_gsm0, ctrl_gsm1, ...], [pert_gsm0, pert_gsm1, ...], extrap_score\n",
    "    '''\n",
    "    undet, ctrl, pert = study_cat\n",
    "    study_group = studies.loc[studies.series_id.isin(\n",
    "        categorized_gse.loc[categorized_gse[\"gse_type\"] == study_cat][\"gse\"])].copy()\n",
    "    if ctrl == 0 and undet == 1: #(1, 0, x)\n",
    "        study_group.replace({'cp_group':{0:\"ctrl_gsm\", 2:\"pert_gsm\"}}, inplace=True)\n",
    "    else:\n",
    "        study_group.replace({'cp_group':{1:\"ctrl_gsm\", 0:\"pert_gsm\", 2:\"pert_gsm\"}}, inplace=True)\n",
    "        \n",
    "    if ctrl == 0 and (undet == 0 or pert == 0):\n",
    "        study_cp_series = study_group.groupby([\"series_id\", \"sample_title_set\"])[\"cp_group\"].unique()\n",
    "        new_ctrl_idx = study_cp_series.index[::2]\n",
    "        study_cp_series[study_cp_series.index.isin(new_ctrl_idx)] = \"ctrl_gsm\"\n",
    "        study_group_map = dict(study_cp_series.explode())\n",
    "        study_group = (study_group.assign(cp_group=study_group[[\"series_id\",\"sample_title_set\"]]\n",
    "                                         .apply(tuple, axis=1).map(study_group_map)))\n",
    "            \n",
    "    return (study_group\n",
    "            .groupby([\"series_id\", \"cp_group\",\"sample_title_set\"])[\"geo_accession\"]\n",
    "            .aggregate(lambda x: list(x))                  # aggregates gsms as a list (ie [gsm1, gsm2, ...])\n",
    "           #.aggregate(lambda x: \"|\".join(x))              # aggregates gsms separated by pipes (ie gsm1|gsm2|...)\n",
    "            .unstack()\n",
    "            .apply(lambda x: list(x.dropna()), axis=1)\n",
    "            .unstack()\n",
    "            .explode(\"ctrl_gsm\")\n",
    "            .explode(\"pert_gsm\")\n",
    "            .assign(extrap_score=extrap_score(study_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid types used to generate final list of gsms for signature calculation\n",
    "valid_types = [(0, 1, 1), (0, 1, 2), (0, 1, 3), \n",
    "               (1, 1, 0), (2, 1, 0), (3, 1, 0), \n",
    "               (0, 0, 2), (2, 0, 0),\n",
    "               (1, 0, 1), (1, 0, 2), (1, 0, 3)]\n",
    "gsm4sig = pd.concat([to_calc_sig_format(i) for i in valid_types]).reset_index()\n",
    "gsm4sig[\"series_id\"] = gsm4sig[\"series_id\"].replace(regex=r\"\\t\", value=\"-\")\n",
    "gsm4sig.to_csv(f\"data/{species}_gsm4sig_v{gsm4sig_version}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
