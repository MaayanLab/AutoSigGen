{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b19b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.feather as feather\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da094119",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['human', 'mouse']\n",
    "direction = [('up', lambda df: df.fc > 0), ('down', lambda df: df.fc < 0)]\n",
    "top_count = 250\n",
    "dash_regex = r\"(?u)\\b\\w[\\w-]*\\w\\b\"  #preserves dashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde75447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human fc done\n",
      "human pval done\n",
      "mouse fc done\n",
      "mouse pval done\n"
     ]
    }
   ],
   "source": [
    "for species in species_list:                                               # converting the csv files to feather files\n",
    "    for dat_type in ['fc', 'pval']:                                        # for quicker access when making gene sets\n",
    "        df = pd.read_csv(f\"all_{species}_{dat_type}.csv\", index_col = 0)   # from each signature, index reset due to \n",
    "        df.rename_axis('genes', inplace = True)                            # feather files not storing index\n",
    "        df.reset_index(inplace = True)\n",
    "        feather.write_feather(df, f\"all_{species}_{dat_type}.feather\")\n",
    "        print(species, dat_type, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a9fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decapitalize(string):\n",
    "    '''\n",
    "    decapitalize the first word if it's not an acronym\n",
    "    '''\n",
    "    try:\n",
    "        first, rest = string.split(\" \", 1)\n",
    "        if not bool(re.search(\"\\B\\w*[A-Z]\\w*\", first)): \n",
    "            first = first.lower()\n",
    "        return f\"{first} {rest}\"\n",
    "    except:\n",
    "        return string\n",
    "\n",
    "def tfidf_shorten_term(idx, vectorizer, term_mat, kept_words = 4):\n",
    "    '''\n",
    "    shorten term based on tf-idf score, keeping kept_words words\n",
    "    '''\n",
    "    row, column = term_mat.getrow(idx).nonzero()\n",
    "    terms = np.array([vectorizer.get_feature_names()[c] for c in column])\n",
    "    if len(terms) <= kept_words: return terms\n",
    "    tfidf_val = np.array([term_mat[idx, c] for c in column])\n",
    "    sorted_val_idx = np.argsort(tfidf_val)[::-1][:kept_words]\n",
    "    return terms[sorted_val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed18251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 human done\n",
      "500 human done\n",
      "1000 human done\n",
      "1500 human done\n",
      "2000 human done\n",
      "2500 human done\n",
      "3000 human done\n",
      "3500 human done\n",
      "4000 human done\n",
      "human done\n",
      "0 mouse done\n",
      "500 mouse done\n",
      "1000 mouse done\n",
      "1500 mouse done\n",
      "2000 mouse done\n",
      "2500 mouse done\n",
      "3000 mouse done\n",
      "3500 mouse done\n",
      "4000 mouse done\n",
      "mouse done\n"
     ]
    }
   ],
   "source": [
    "for species in species_list:\n",
    "    gmt_tuples = {'up':[], 'down':[]}\n",
    "    master_df = pd.read_csv(f\"all_{species}_score.csv\", index_col = 0)\n",
    "    for n, col in enumerate(master_df.columns):\n",
    "        # identifying top top_count up and down genes for each signature\n",
    "        try:\n",
    "            if n % 500 == 0: print(n, species, 'done')\n",
    "            title, gse = col.rsplit(\" \", 1)\n",
    "            fc_df = feather.read_feather(f\"all_{species}_fc.feather\", columns = [\"genes\", col]).set_index('genes')\n",
    "            pval_df = feather.read_feather(f\"all_{species}_pval.feather\", columns = [\"genes\", col]).set_index('genes')\n",
    "            comb_df = pd.concat([fc_df, pval_df], axis=1)\n",
    "            comb_df.columns = ['fc', 'pval']\n",
    "            for d, d_func in direction:                                                     # subsetting based on fc sign\n",
    "                top_genes = list(comb_df[d_func].sort_values(by='pval').index[:top_count])  # sorting based on pval magnitude\n",
    "                gmt_tuples[d].append((gse, title, *top_genes))\n",
    "        except:\n",
    "            print(col)\n",
    "    \n",
    "    # creating raw [human, mouse] x [up, down] gene set library gmt files\n",
    "    # row: {gse id}_{signature number}\\t{gse title}\\tGENE_1\\tGENE_2\\t...\\tGENE_{top_count}\n",
    "    pd.DataFrame(gmt_tuples['up']).to_csv(f\"{species}_up_gene_set_raw.gmt\", index = False, header = False, sep = \"\\t\")\n",
    "    pd.DataFrame(gmt_tuples['down']).to_csv(f\"{species}_down_gene_set_raw.gmt\", index = False, header = False, sep = \"\\t\")\n",
    "    print(species, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654a7ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting human\n",
      "making raw_key_terms...\n",
      "done making raw_key_terms\n",
      "preparing up file for human...\n",
      "done preparing up file for human\n",
      "preparing down file for human...\n",
      "done preparing down file for human\n",
      "term name length distribution for human:\n",
      "(-0.001, 10.0]       0\n",
      "(10.0, 20.0]         4\n",
      "(20.0, 30.0]        42\n",
      "(30.0, 40.0]       806\n",
      "(40.0, 50.0]      2011\n",
      "(50.0, 60.0]      1170\n",
      "(60.0, 70.0]       208\n",
      "(70.0, 80.0]        27\n",
      "(80.0, 90.0]         1\n",
      "(90.0, 100.0]        0\n",
      "dtype: int64\n",
      "done with human\n",
      "starting mouse\n",
      "making raw_key_terms...\n",
      "done making raw_key_terms\n",
      "preparing up file for mouse...\n",
      "done preparing up file for mouse\n",
      "preparing down file for mouse...\n",
      "done preparing down file for mouse\n",
      "term name length distribution for mouse:\n",
      "(-0.001, 10.0]       0\n",
      "(10.0, 20.0]         4\n",
      "(20.0, 30.0]        65\n",
      "(30.0, 40.0]       881\n",
      "(40.0, 50.0]      1915\n",
      "(50.0, 60.0]      1121\n",
      "(60.0, 70.0]       204\n",
      "(70.0, 80.0]        26\n",
      "(80.0, 90.0]         0\n",
      "(90.0, 100.0]        0\n",
      "dtype: int64\n",
      "done with mouse\n"
     ]
    }
   ],
   "source": [
    "for species in species_list:\n",
    "    print(\"starting\", species)\n",
    "    gmt = pd.read_csv(f\"{species}_up_gene_set_raw.gmt\", header = None, usecols = [1], sep = \"\\t\")\n",
    "    gmt.columns = [\"raw_titles\"]\n",
    "    gmt.fillna(\"\", inplace = True) # certain studies had their metadata privatized on GEO so no title\n",
    "    gmt[\"titles\"] = gmt[\"raw_titles\"].apply(decapitalize)\n",
    "    gmt_unique = pd.DataFrame(data = gmt[\"titles\"].unique(), columns = [\"unique_titles\"])\n",
    "    # list of terms found in each unique title, respecting dashes via regex\n",
    "    gmt_unique[\"unique_list\"] = gmt_unique[\"unique_titles\"].apply(str.lower).str.findall(dash_regex)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words = 'english', token_pattern = dash_regex)\n",
    "    term_mat = vectorizer.fit_transform(gmt_unique[\"unique_titles\"])\n",
    "    \n",
    "    print('making raw_key_terms...')\n",
    "    #list of top tf-idf terms for each unique title, in order of tf-idf score\n",
    "    gmt_unique[\"raw_key_terms\"] = [tfidf_shorten_term(i, vectorizer, term_mat) for i in gmt_unique.index]\n",
    "    print('done making raw_key_terms')\n",
    "    #list of top if-idf terms for each unique title, in order of term appearance in title\n",
    "    gmt_unique[\"key_terms_ordered\"] = [sorted(gmt_unique[\"raw_key_terms\"][i], \n",
    "                                              key=lambda x: gmt_unique[\"unique_list\"][i].index(x)) \\\n",
    "                                       for i in gmt_unique.index]\n",
    "    #string concatenation of ordered top tf-idf terms, to use as part of tf-idf shortened title\n",
    "    gmt_unique[\"key_terms\"] = gmt_unique[\"key_terms_ordered\"].apply(\" \".join)\n",
    "    matched_titles = gmt[[\"titles\"]].merge(gmt_unique[[\"unique_titles\", \"key_terms\"]], how = 'left', \n",
    "                                           left_on = \"titles\", right_on = \"unique_titles\")\n",
    "    \n",
    "    for d,_ in direction:\n",
    "        print(f\"preparing {d} file for {species}...\")\n",
    "        new_gmt = pd.read_csv(f\"{species}_{d}_gene_set_raw.gmt\", header = None, sep = \"\\t\")\n",
    "        new_term_names = matched_titles[\"key_terms\"] + \" \" + new_gmt[0]\n",
    "        \n",
    "        # creating modified [human, mouse] x [up, down] gene set library gmt files\n",
    "        # row: {shortened_gse_titles {gse id}_{signature number}}\\t{gse title}\\tGENE_1\\tGENE_2\\t...\\tGENE_n\n",
    "        pd.concat([new_term_names, new_gmt[new_gmt.columns[1:]]], axis = 1).to_csv(f\"{species}_{d}_gene_set.gmt\", \n",
    "                                                                                   index = False, header = False, sep = \"\\t\")\n",
    "        print(f\"done preparing {d} file for {species}\")\n",
    "    print(f\"term name length distribution for {species}:\")\n",
    "    print(new_term_names.apply(len).value_counts(bins=range(0, 110, 10)).sort_index())\n",
    "    print('done with', species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091579b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
