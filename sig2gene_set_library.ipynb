{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b19b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.feather as feather\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da094119",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['human', 'mouse']\n",
    "direction = [('up', lambda df: df.fc > 0), ('down', lambda df: df.fc < 0)]\n",
    "top_count = 250\n",
    "dash_regex = r\"(?u)\\b\\w[\\w-]*\\w\\b\"  #preserves dashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde75447",
   "metadata": {},
   "outputs": [],
   "source": [
    "for species in species_list:                                               # converting the csv files to feather files\n",
    "    for dat_type in ['fc', 'pval']:                                        # for quicker access when making gene sets\n",
    "        df = pd.read_csv(f\"all_{species}_{dat_type}.csv\", index_col = 0)   # from each signature, index reset due to \n",
    "        df.rename_axis('genes', inplace = True)                            # feather files not storing index\n",
    "        df.reset_index(inplace = True)\n",
    "        feather.write_feather(df, f\"all_{species}_{dat_type}.feather\")\n",
    "        print(species, dat_type, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decapitalize(string):\n",
    "    '''\n",
    "    decapitalize the first word if it's not an acronym\n",
    "    '''\n",
    "    try:\n",
    "        first, rest = string.split(\" \", 1)\n",
    "        if not bool(re.search(\"\\B\\w*[A-Z]\\w*\", first)): \n",
    "            first = first.lower()\n",
    "        return f\"{first} {rest}\"\n",
    "    except:\n",
    "        return string\n",
    "\n",
    "def tfidf_shorten_term(idx, vectorizer, term_mat, kept_words = 4):\n",
    "    '''\n",
    "    shorten term based on tf-idf score, keeping kept_words words\n",
    "    '''\n",
    "    row, column = term_mat.getrow(idx).nonzero()\n",
    "    terms = np.array([vectorizer.get_feature_names()[c] for c in column])\n",
    "    if len(terms) <= kept_words: return terms\n",
    "    tfidf_val = np.array([term_mat[idx, c] for c in column])\n",
    "    sorted_val_idx = np.argsort(tfidf_val)[::-1][:kept_words]\n",
    "    return terms[sorted_val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed18251",
   "metadata": {},
   "outputs": [],
   "source": [
    "for species in species_list:\n",
    "    gmt_tuples = {'up':[], 'down':[]}\n",
    "    master_df = pd.read_csv(f\"all_{species}_score.csv\", index_col = 0)\n",
    "    for n, col in enumerate(master_df.columns):\n",
    "        # identifying top top_count up and down genes for each signature\n",
    "        try:\n",
    "            if n % 500 == 0: print(n, species, 'done')\n",
    "            title, gse = col.rsplit(\" \", 1)\n",
    "            fc_df = feather.read_feather(f\"all_{species}_fc.feather\", columns = [\"genes\", col]).set_index('genes')\n",
    "            pval_df = feather.read_feather(f\"all_{species}_pval.feather\", columns = [\"genes\", col]).set_index('genes')\n",
    "            comb_df = pd.concat([fc_df, pval_df], axis=1)\n",
    "            comb_df.columns = ['fc', 'pval']\n",
    "            for d, d_func in direction:                                                     # subsetting based on fc sign\n",
    "                top_genes = list(comb_df[d_func].sort_values(by='pval').index[:top_count])  # sorting based on pval magnitude\n",
    "                gmt_tuples[d].append((gse, title, *top_genes))\n",
    "        except:\n",
    "            print(col)\n",
    "    \n",
    "    # creating raw [human, mouse] x [up, down] gene set library gmt files\n",
    "    # row: {gse id}_{signature number}\\t{gse title}\\tGENE_1\\tGENE_2\\t...\\tGENE_{top_count}\n",
    "    pd.DataFrame(gmt_tuples['up']).to_csv(f\"{species}_up_gene_set_raw.gmt\", index = False, header = False, sep = \"\\t\")\n",
    "    pd.DataFrame(gmt_tuples['down']).to_csv(f\"{species}_down_gene_set_raw.gmt\", index = False, header = False, sep = \"\\t\")\n",
    "    print(species, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for species in species_list:\n",
    "    print(\"starting\", species)\n",
    "    gmt = pd.read_csv(f\"{species}_up_gene_set_raw.gmt\", header = None, usecols = [1], sep = \"\\t\")\n",
    "    gmt.columns = [\"raw_titles\"]\n",
    "    gmt.fillna(\"\", inplace = True) # certain studies had their metadata privatized on GEO so no title\n",
    "    gmt[\"titles\"] = gmt[\"raw_titles\"].apply(decapitalize)\n",
    "    gmt_unique = pd.DataFrame(data = gmt[\"titles\"].unique(), columns = [\"unique_titles\"])\n",
    "    # list of terms found in each unique title, respecting dashes via regex\n",
    "    gmt_unique[\"unique_list\"] = gmt_unique[\"unique_titles\"].apply(str.lower).str.findall(dash_regex)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words = 'english', token_pattern = dash_regex)\n",
    "    term_mat = vectorizer.fit_transform(gmt_unique[\"unique_titles\"])\n",
    "    \n",
    "    print('making raw_key_terms...')\n",
    "    #list of top tf-idf terms for each unique title, in order of tf-idf score\n",
    "    gmt_unique[\"raw_key_terms\"] = [tfidf_shorten_term(i, vectorizer, term_mat) for i in gmt_unique.index]\n",
    "    print('done making raw_key_terms')\n",
    "    #list of top if-idf terms for each unique title, in order of term appearance in title\n",
    "    gmt_unique[\"key_terms_ordered\"] = [sorted(gmt_unique[\"raw_key_terms\"][i], \n",
    "                                              key=lambda x: gmt_unique[\"unique_list\"][i].index(x)) \\\n",
    "                                       for i in gmt_unique.index]\n",
    "    #string concatenation of ordered top tf-idf terms, to use as part of tf-idf shortened title\n",
    "    gmt_unique[\"key_terms\"] = gmt_unique[\"key_terms_ordered\"].apply(\" \".join)\n",
    "    matched_titles = gmt[[\"titles\"]].merge(gmt_unique[[\"unique_titles\", \"key_terms\"]], how = 'left', \n",
    "                                           left_on = \"titles\", right_on = \"unique_titles\")\n",
    "    \n",
    "    for d,_ in direction:\n",
    "        print(f\"preparing {d} file for {species}...\")\n",
    "        new_gmt = pd.read_csv(f\"{species}_{d}_gene_set_raw.gmt\", header = None, sep = \"\\t\")\n",
    "        new_term_names = matched_titles[\"key_terms\"] + \" \" + new_gmt[0]\n",
    "        \n",
    "        # creating modified [human, mouse] x [up, down] gene set library gmt files\n",
    "        # row: {shortened_gse_titles {gse id}_{signature number}}\\t{gse title}\\tGENE_1\\tGENE_2\\t...\\tGENE_n\n",
    "        pd.concat([new_term_names, new_gmt[new_gmt.columns[1:]]], axis = 1).to_csv(f\"{species}_{d}_gene_set.gmt\", \n",
    "                                                                                   index = False, header = False, sep = \"\\t\")\n",
    "        print(f\"done preparing {d} file for {species}\")\n",
    "    print(f\"term name length distribution for {species}:\")\n",
    "    print(new_term_names.apply(len).value_counts(bins=range(0, 110, 10)).sort_index())\n",
    "    print('done with', species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091579b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
